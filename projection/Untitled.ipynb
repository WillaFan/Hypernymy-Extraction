{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypernymy discovery using projection learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SemEval2018-Task9 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading candidates from vocabulary ...\n",
      "Loading queries from './data/SemEval2018-Task9/vocabulary/2B.music.vocabulary.txt' ...\n",
      "Loading queries from './data/SemEval2018-Task9/training/data/2B.music.training.data.txt' ...\n",
      "Loading queries from './data/SemEval2018-Task9/trial/data/2B.music.trial.data.txt' ...\n",
      "# of candidates: 69118\n",
      "# of queries: 1014\n",
      "\n",
      "Size of vocab: 69336\n",
      "# of unigrams: 58394\n",
      "# of bigrams: 9749\n",
      "# of trigrams: 1193\n",
      "Counting lines in corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [00:00, 34599.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting n-gram frequencies in corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4298453it [02:54, 24681.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4298453/4298453 lines processed. Vocab coverage: 69336/69336.\n",
      "# of zero-frequency queries: 0\n",
      "# of zero-frequency candidates: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Load candidates and queries\n",
    "# queries: data |hypos; candidates: vocabulary |hypers (total)\n",
    "\n",
    "from preprocess import *\n",
    "se = Dataset()\n",
    "candidates, queries = se.load_vocab('./data/SemEval2018-Task9', lower_queries=True)\n",
    "\n",
    "\n",
    "# ```````````````````````````````````````````````````````````````\n",
    "# Check\n",
    "print(\"# of candidates: {}\".format(len(candidates)))\n",
    "print(\"# of queries: {}\".format(len(queries)))\n",
    "\n",
    "vocab = candidates.union(queries)\n",
    "print(\"\\nSize of vocab: {}\".format(len(vocab)))\n",
    "\n",
    "unigrams, bigrams, trigrams = is_ngram(vocab)\n",
    "print(\"# of unigrams: {}\".format(len(unigrams)))\n",
    "print(\"# of bigrams: {}\".format(len(bigrams)))\n",
    "print(\"# of trigrams: {}\".format(len(trigrams)))\n",
    "# ```````````````````````````````````````````````````````````````\n",
    "\n",
    "\n",
    "# 2. Preprocess the corpus\n",
    "# 2.1 Count n-gram frequencies in corpus\n",
    "term_to_freq_in = n_gram_count(\"./data/2B_music_bioreviews_tokenized.txt\", vocab)\n",
    "\n",
    "nb_missing_q = sum(1 for w in queries if term_to_freq_in[w] == 0)\n",
    "nb_missing_c = sum(1 for w in candidates if term_to_freq_in[w] == 0)\n",
    "print(\"# of zero-frequency queries: {}\".format(nb_missing_q))\n",
    "print(\"# of zero-frequency candidates: {}\".format(nb_missing_c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**preprocess the corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1571it [00:00, 15616.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4298453it [03:15, 22013.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of missing queries in output: 0\n",
      "# of missing candidates in output: 21\n",
      "Examples: amyotrophic, australian rules, electroconvulsive, esophageal, giardiniera, gluteus, holies, hyoscyamus, impinge, infarction, inkjet, longlegs, matrix printer, maundy, pancreatic, propping, reductio, rheumatoid, signal-to-noise, strep, whole shebang\n",
      "Finished...\n",
      "\n",
      "Wrote corpus to './f_out_preprocessed_corpus.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Replace multi-word terms with single tokens and write into files\n",
    "# n-gram --> sigle token\n",
    "replace_OOV = True\n",
    "\n",
    "corpus = \"./data/2B_music_bioreviews_tokenized.txt\"\n",
    "preprocessed = \"./f_out_preprocessed_corpus.txt\"\n",
    "term_to_freq_out = preprocess_corpus(corpus, preprocessed, queries, candidates, term_to_freq_in, replace_OOV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote vocab to './f_out.vocab.txt'\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Write frequencies\n",
    "vocab_out_name = \"f_out\"\n",
    "write_freq(vocab_out_name, term_to_freq_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train word embeddings on corpus using word2vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train embeddings\n",
    "from embed import *\n",
    "\n",
    "preprocessed_corpus_path = \"./f_out_preprocessed_corpus.txt\"\n",
    "save_embed_path = \"./replace_OOV_\" + str(replace_OOV) + \"_word2vec_model\"\n",
    "#-cbow 0 -negative 10 -size 200 -window 7 -sample 1e-5 -min-count 1 -iter 10 -threads 8 -binary 0\n",
    "train_embed(preprocessed_corpus_path, save_embed_path, size=200, window=7, min_count=1, workers=3, sg=0, negative=10, sample=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embedding\n",
    "embeddings = load_embed(save_embed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for art_rock:  [-0.23230837  0.01129624  0.13712774  0.2948994   0.32275087  0.10951022\n",
      " -1.2290376  -0.7920031   0.80765796 -0.5433384  -0.31529322  0.22816107\n",
      "  0.06184823 -0.37818426  0.22129554 -0.4265703   0.6036683  -0.7077877\n",
      " -0.03365989  0.40926868 -0.35232663  0.3912602   0.42833325 -0.6010476\n",
      " -0.4191413  -0.87336016 -0.00455265  0.9714704  -0.11817481  1.188886\n",
      " -1.0646467   0.9814277   1.0018854   0.38089174  0.7176756   0.00531878\n",
      " -0.61265355 -0.3516089   0.14747235 -0.4422404   0.11448751 -0.3273031\n",
      " -1.0525167  -0.6365699   0.10880286 -1.2576685  -0.10639022  1.1753112\n",
      "  0.8095967  -0.05291764  0.16562843  0.2761667   0.05437643 -0.1625104\n",
      " -0.5321007   0.62873125 -0.00801373 -0.53174585 -0.27858248  0.36114895\n",
      " -1.2442654  -0.08463544 -0.42626226 -1.0270053   0.7380261   0.5169968\n",
      " -0.45904094  0.4419561  -1.3959762   1.1092414   0.039956    0.2952897\n",
      " -0.38187805  0.02782012 -0.20733292  0.9550967   0.43262872 -0.865123\n",
      "  0.15561125  0.1213872  -0.17276989  0.1773125  -0.09746221  0.15660824\n",
      "  0.24106836  0.57680565 -1.4905525  -1.5949332   0.1496594  -0.48752946\n",
      " -1.1542283  -0.62708926 -0.28008056 -0.5780757   1.0856192   0.33877033\n",
      "  0.15139347 -0.45454776  0.22418034  0.15173066  0.04594041 -0.3788511\n",
      " -0.57095873 -0.8548429  -0.6238101  -0.26652655 -0.56745845  0.5302608\n",
      " -0.10480651 -0.43896523 -0.3664007   0.30657515  0.56441504 -0.9537668\n",
      " -0.4247774   0.50205183  1.175033   -0.55342424 -0.27133644  0.7135379\n",
      "  0.1917815  -1.8794472  -0.898055    0.2777698   0.34876564 -0.14554186\n",
      "  0.05798068  0.83886886  0.38085586 -0.73098344  0.5035379  -0.86300355\n",
      " -0.30331936 -0.49349514 -0.45039037 -0.75245255  0.5249853   0.6429007\n",
      " -0.47884908 -0.99884063 -0.38966507 -0.4022974   0.3284501   0.15576965\n",
      " -0.5127345   0.5637749   0.20282723 -0.12753268 -0.28964654 -0.06588202\n",
      " -0.11365108  0.35724473  0.15346453  0.27573726  0.18084224 -1.1481224\n",
      "  1.3695691   0.43636382  0.14131121 -0.8771455  -0.15410227 -0.144953\n",
      " -0.08819669 -0.49187565 -0.20407009  0.70464355  0.5268656  -0.3640129\n",
      "  0.44047007  1.2079546   1.5700947  -0.04000356  0.01463877  0.56482536\n",
      "  0.7608249   0.7291433  -0.06695084 -0.5294899  -0.1951515   0.38828018\n",
      " -0.7271563  -0.26872316  0.13674077 -1.8055083   0.6142795  -0.17602502\n",
      "  1.0314821  -0.02944713 -0.39815536  0.09013833 -0.374936   -0.00215439\n",
      "  0.7975407   0.38036034  1.0414788  -0.14980718  0.23659325  0.19498546\n",
      "  0.36854452  0.9563303 ]\n",
      "Embedding for art_rock:  [-0.23230837  0.01129624  0.13712774  0.2948994   0.32275087  0.10951022\n",
      " -1.2290376  -0.7920031   0.80765796 -0.5433384  -0.31529322  0.22816107\n",
      "  0.06184823 -0.37818426  0.22129554 -0.4265703   0.6036683  -0.7077877\n",
      " -0.03365989  0.40926868 -0.35232663  0.3912602   0.42833325 -0.6010476\n",
      " -0.4191413  -0.87336016 -0.00455265  0.9714704  -0.11817481  1.188886\n",
      " -1.0646467   0.9814277   1.0018854   0.38089174  0.7176756   0.00531878\n",
      " -0.61265355 -0.3516089   0.14747235 -0.4422404   0.11448751 -0.3273031\n",
      " -1.0525167  -0.6365699   0.10880286 -1.2576685  -0.10639022  1.1753112\n",
      "  0.8095967  -0.05291764  0.16562843  0.2761667   0.05437643 -0.1625104\n",
      " -0.5321007   0.62873125 -0.00801373 -0.53174585 -0.27858248  0.36114895\n",
      " -1.2442654  -0.08463544 -0.42626226 -1.0270053   0.7380261   0.5169968\n",
      " -0.45904094  0.4419561  -1.3959762   1.1092414   0.039956    0.2952897\n",
      " -0.38187805  0.02782012 -0.20733292  0.9550967   0.43262872 -0.865123\n",
      "  0.15561125  0.1213872  -0.17276989  0.1773125  -0.09746221  0.15660824\n",
      "  0.24106836  0.57680565 -1.4905525  -1.5949332   0.1496594  -0.48752946\n",
      " -1.1542283  -0.62708926 -0.28008056 -0.5780757   1.0856192   0.33877033\n",
      "  0.15139347 -0.45454776  0.22418034  0.15173066  0.04594041 -0.3788511\n",
      " -0.57095873 -0.8548429  -0.6238101  -0.26652655 -0.56745845  0.5302608\n",
      " -0.10480651 -0.43896523 -0.3664007   0.30657515  0.56441504 -0.9537668\n",
      " -0.4247774   0.50205183  1.175033   -0.55342424 -0.27133644  0.7135379\n",
      "  0.1917815  -1.8794472  -0.898055    0.2777698   0.34876564 -0.14554186\n",
      "  0.05798068  0.83886886  0.38085586 -0.73098344  0.5035379  -0.86300355\n",
      " -0.30331936 -0.49349514 -0.45039037 -0.75245255  0.5249853   0.6429007\n",
      " -0.47884908 -0.99884063 -0.38966507 -0.4022974   0.3284501   0.15576965\n",
      " -0.5127345   0.5637749   0.20282723 -0.12753268 -0.28964654 -0.06588202\n",
      " -0.11365108  0.35724473  0.15346453  0.27573726  0.18084224 -1.1481224\n",
      "  1.3695691   0.43636382  0.14131121 -0.8771455  -0.15410227 -0.144953\n",
      " -0.08819669 -0.49187565 -0.20407009  0.70464355  0.5268656  -0.3640129\n",
      "  0.44047007  1.2079546   1.5700947  -0.04000356  0.01463877  0.56482536\n",
      "  0.7608249   0.7291433  -0.06695084 -0.5294899  -0.1951515   0.38828018\n",
      " -0.7271563  -0.26872316  0.13674077 -1.8055083   0.6142795  -0.17602502\n",
      "  1.0314821  -0.02944713 -0.39815536  0.09013833 -0.374936   -0.00215439\n",
      "  0.7975407   0.38036034  1.0414788  -0.14980718  0.23659325  0.19498546\n",
      "  0.36854452  0.9563303 ]\n",
      "\n",
      "First 20 vocabulary words: ['<UNK>', 'album', 'quot', 'one', 'like', 'cd', 'song', 'band', 'great', 'just', 'first', 'love', 'best', 'new', 'sound', 'will', 'really', 'well', 'track', 'still']\n",
      "\n",
      "Vocabulary size: 69316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wfanae\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\wfanae\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\wfanae\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "c:\\users\\wfanae\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# try\n",
    "# i. Query for the word embeddings of a given word\n",
    "print('Embedding for art_rock: ',embeddings.wv['art_rock'])\n",
    "print('Embedding for art_rock: ',embeddings.wv['art_rock'])\n",
    "\n",
    "# ii. Inspect the model vocabulary\n",
    "# print the first 20 words\n",
    "print('\\nFirst 20 vocabulary words:',list(embeddings.wv.vocab)[:20])\n",
    "print('\\nVocabulary size:',len(list(embeddings.wv.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. vocabulary (hypo-hyper pairs) to embeddings\n",
    "write_embed_path = \"./embeddings.txt\"\n",
    "write_embed(save_embed_path, write_embed_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**preprocess data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of candidates: 69118\n",
      "\n",
      "Loading queries...\n",
      "# of training queries: 500\n",
      "# of dev queries: 15\n",
      "# of test queries: 500\n"
     ]
    }
   ],
   "source": [
    "# 5. Load data\n",
    "# candidates\n",
    "print(\"# of candidates: {}\".format(len(candidates)))\n",
    "# Load queries\n",
    "print(\"\\nLoading queries...\")\n",
    "path_q_train = \"{}/training/data/{}.training.data.txt\".format(\"./data/SemEval2018-Task9\", \"2B.music\")\n",
    "path_q_dev = \"{}/trial/data/{}.trial.data.txt\".format(\"./data/SemEval2018-Task9\", \"2B.music\")\n",
    "path_q_test = \"{}/test/data/{}.test.data.txt\".format(\"./data/SemEval2018-Task9\", \"2B.music\")\n",
    "q_train, _ = se.load_queries(path_q_train, normalize=True)\n",
    "q_dev, _ = se.load_queries(path_q_dev, normalize=True)\n",
    "q_test, _ = se.load_queries(path_q_test, normalize=True)\n",
    "print(\"# of training queries: {}\".format(len(q_train)))\n",
    "print(\"# of dev queries: {}\".format(len(q_dev)))\n",
    "print(\"# of test queries: {}\".format(len(q_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gold hypernyms...\n",
      "# of training pairs: 5455\n",
      "# of dev pairs: 355\n"
     ]
    }
   ],
   "source": [
    "# Load gold hypernyms (train and dev only)\n",
    "print(\"Loading gold hypernyms...\")\n",
    "path_h_train = \"{}/training/gold/{}.training.gold.txt\".format(\"./data/SemEval2018-Task9\", \"2B.music\")\n",
    "path_h_dev = \"{}/trial/gold/{}.trial.gold.txt\".format(\"./data/SemEval2018-Task9\", \"2B.music\")\n",
    "h_train = se.load_hypernyms(path_h_train)\n",
    "h_dev = se.load_hypernyms(path_h_dev, normalize=True)\n",
    "print(\"# of training pairs: {}\".format(sum(len(x) for x in h_train)))\n",
    "print(\"# of dev pairs: {}\".format(sum(len(x) for x in h_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained word embeddings...\n",
      "# of embeddings: 69316\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading pre-trained word embeddings...\")\n",
    "embed_vocab_list, word2vec = get_embeddings(\"./embeddings.txt\", np.float32)\n",
    "embed_vocab_set = set(embed_vocab_list)\n",
    "print(\"# of embeddings: {}\".format(len(embed_vocab_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making embedding array for candidates...\n",
      "# of embeddings: 69118\n",
      "Making embedding array for training queries...\n",
      "# of embeddings: 500\n",
      "Making embedding array for dev queries...\n",
      "# of embeddings: 15\n",
      "Making embedding array for test queries...\n",
      "# of embeddings: 500\n"
     ]
    }
   ],
   "source": [
    "# 6. Preparing embeddings for data\n",
    "print(\"Making embedding array for candidates...\")\n",
    "candidate_embeds = make_embedding_matrix(word2vec, candidates, seed=91500)\n",
    "candidate_embeds = normalize_numpy_matrix(candidate_embeds)\n",
    "print(\"# of embeddings: {}\".format(candidate_embeds.shape[0]))\n",
    "print(\"Making embedding array for training queries...\")\n",
    "train_query_embeds = make_embedding_matrix(word2vec, q_train, seed=91500)\n",
    "train_query_embeds = normalize_numpy_matrix(train_query_embeds)\n",
    "print(\"# of embeddings: {}\".format(train_query_embeds.shape[0]))\n",
    "print(\"Making embedding array for dev queries...\")\n",
    "dev_query_embeds = make_embedding_matrix(word2vec, q_dev, seed=91500)\n",
    "dev_query_embeds = normalize_numpy_matrix(dev_query_embeds)\n",
    "print(\"# of embeddings: {}\".format(dev_query_embeds.shape[0]))\n",
    "print(\"Making embedding array for test queries...\")\n",
    "test_query_embeds = make_embedding_matrix(word2vec, q_test, seed=91500)\n",
    "test_query_embeds = normalize_numpy_matrix(test_query_embeds)\n",
    "print(\"# of embeddings: {}\".format(test_query_embeds.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of embed vocabulary:  69316\n",
      "# of candidates:  69118\n",
      "# of cand in embed vocab:  58327\n",
      "-- Assign a random vector to words that don't have one. --\n",
      "# of h_train:  5455\n",
      "# of h_dev:  355\n",
      "# of h_train in cand:  2651\n",
      "# of h_dev in cand:  231\n"
     ]
    }
   ],
   "source": [
    "print(\"# of embed vocabulary: \",len(embed_vocab_set))\n",
    "# print(candidates)  #--vocabulary\n",
    "# print(h_train)  #--gold\n",
    "cand_in_embed_vocab=[x for x in candidates if x in embed_vocab_set]\n",
    "flat_h_train=[x for list in h_train for x in list]\n",
    "flat_h_dev=[x for list in h_dev for x in list]\n",
    "h_train_in_cand=[x for x in flat_h_train if x in candidates]  #--gold in vocabulary\n",
    "h_dev_in_cand=[x for x in flat_h_dev if x in candidates]  #--gold in vocabulary\n",
    "print(\"# of candidates: \",len(candidates))\n",
    "print(\"# of cand in embed vocab: \",len(cand_in_embed_vocab))\n",
    "print(\"-- Assign a random vector to words that don't have one. --\")\n",
    "print(\"# of h_train: \",len(flat_h_train))\n",
    "print(\"# of h_dev: \",len(flat_h_dev))\n",
    "print(\"# of h_train in cand: \",len(h_train_in_cand))\n",
    "print(\"# of h_dev in cand: \",len(h_dev_in_cand))\n",
    "# why some candidate not in embed vocab?\n",
    "# why some gold not in candidate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making array of (query ID, hypernym ID) pairs...\n",
      "# of train pairs: 500\n",
      "# of dev pairs: 15\n",
      "# of training queries that are also candidates: 248\n",
      "# of dev queries that are also candidates: 7\n",
      "# of test queries that are also candidates: 250\n"
     ]
    }
   ],
   "source": [
    "# Make array of (query IDs, hypernym IDs) pairs for model training\n",
    "print(\"Making array of (query ID, hypernym ID) pairs...\")\n",
    "candidate_to_id = {w:i for i,w in enumerate(candidates)}\n",
    "train_query_to_id = {w:i for i,w in enumerate(q_train)}\n",
    "dev_query_to_id = {w:i for i,w in enumerate(q_dev)}\n",
    "\n",
    "# train_pairs = make_pairs(q_train, h_train, train_query_to_id, candidate_to_id)\n",
    "# dev_pairs = make_pairs(q_dev, h_dev, dev_query_to_id, candidate_to_id)\n",
    "###### temporarily use hypers already in candidates\n",
    "train_pairs = make_pairs(q_train, h_train_in_cand, train_query_to_id, candidate_to_id)\n",
    "dev_pairs = make_pairs(q_dev, h_dev_in_cand, dev_query_to_id, candidate_to_id)\n",
    "\n",
    "print(\"# of train pairs: {}\".format(train_pairs.shape[0]))\n",
    "print(\"# of dev pairs: {}\".format(dev_pairs.shape[0]))\n",
    "    \n",
    "# Check for queries that are also candidates. Make list of query\n",
    "# candidate IDs (None for queries that are not candidates)\n",
    "train_q_cand_ids = [candidate_to_id[q] if q in candidate_to_id else None for q in q_train]\n",
    "dev_q_cand_ids = [candidate_to_id[q] if q in candidate_to_id else None for q in q_dev]\n",
    "test_q_cand_ids = [candidate_to_id[q] if q in candidate_to_id else None for q in q_test]\n",
    "nb_cand_q_train = sum(1 for i in train_q_cand_ids if i is not None)\n",
    "nb_cand_q_dev = sum(1 for i in dev_q_cand_ids if i is not None)\n",
    "nb_cand_q_test = sum(1 for i in test_q_cand_ids if i is not None)\n",
    "print(\"# of training queries that are also candidates: {}\".format(nb_cand_q_train))\n",
    "print(\"# of dev queries that are also candidates: {}\".format(nb_cand_q_dev))\n",
    "print(\"# of test queries that are also candidates: {}\".format(nb_cand_q_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data:\n",
      "- candidates (builtins.set)\n",
      "- candidate_embeds (numpy.ndarray)\n",
      "- train_queries (builtins.list)\n",
      "- train_query_embeds (numpy.ndarray)\n",
      "- train_query_cand_ids (builtins.list)\n",
      "- dev_queries (builtins.list)\n",
      "- dev_query_embeds (numpy.ndarray)\n",
      "- dev_query_cand_ids (builtins.list)\n",
      "- test_queries (builtins.list)\n",
      "- test_query_embeds (numpy.ndarray)\n",
      "- test_query_cand_ids (builtins.list)\n",
      "- train_pairs (numpy.ndarray)\n",
      "- dev_pairs (numpy.ndarray)\n",
      "\n",
      "Wrote data to './dumped.data'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Pickle and dump data\n",
    "import joblib\n",
    "    \n",
    "data = {}\n",
    "data[\"candidates\"] = candidates\n",
    "data[\"candidate_embeds\"] = candidate_embeds\n",
    "data[\"train_queries\"] = q_train\n",
    "data[\"train_query_embeds\"] = train_query_embeds\n",
    "data[\"train_query_cand_ids\"] = train_q_cand_ids\n",
    "data[\"dev_queries\"] = q_dev\n",
    "data[\"dev_query_embeds\"] = dev_query_embeds\n",
    "data[\"dev_query_cand_ids\"] = dev_q_cand_ids\n",
    "data[\"test_queries\"] = q_test\n",
    "data[\"test_query_embeds\"] = test_query_embeds\n",
    "data[\"test_query_cand_ids\"] = test_q_cand_ids\n",
    "data[\"train_pairs\"] = train_pairs\n",
    "data[\"dev_pairs\"] = dev_pairs\n",
    "print(\"\\nData:\")\n",
    "for k,v in data.items():\n",
    "    print(\"- {} ({}.{})\".format(k, type(v).__module__, type(v).__name__))\n",
    "joblib.dump(data, \"./dumped.data\")\n",
    "print(\"\\nWrote data to '{}'\\n\".format(\"./dumped.data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train model on training and dev data in pickle file, write a model and a log file in dir-model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data:\n",
      "- candidates (builtins.set)\n",
      "- candidate_embeds (numpy.ndarray)\n",
      "- train_queries (builtins.list)\n",
      "- train_query_embeds (numpy.ndarray)\n",
      "- train_query_cand_ids (builtins.list)\n",
      "- dev_queries (builtins.list)\n",
      "- dev_query_embeds (numpy.ndarray)\n",
      "- dev_query_cand_ids (builtins.list)\n",
      "- test_queries (builtins.list)\n",
      "- test_query_embeds (numpy.ndarray)\n",
      "- test_query_cand_ids (builtins.list)\n",
      "- train_pairs (numpy.ndarray)\n",
      "- dev_pairs (numpy.ndarray)\n",
      "\n",
      "Initializing model...\n",
      "Model parameters:\n",
      "- projector.pmats (on CPU, grad=yes) \n",
      "- projector.cand_embed.weight (on CPU, grad=yes) \n",
      "- output.weight (on CPU, grad=yes) \n",
      "- output.bias (on CPU, grad=yes) \n",
      "\n",
      "Evaluating untrained model on dev set...\n",
      "MAP: 0.0000\n",
      "AP: 0.0000\n",
      "MRR: 0.0000\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Epoch\tUpdates\tPosLoss\tNegLoss\tDevLoss\tDevMAP\tDevAP\tDevMRR\tTimeElapsed\n",
      "1\t16\t0.6992\t7.0832\t0.6754\t0.0000\t0.0000\t0.0000\t8.3s\n",
      "2\t17\t0.7179\t6.5686\t0.7035\t0.0000\t0.0000\t0.0000\t15.9s\n",
      "3\t16\t0.7436\t6.1078\t0.7308\t0.0000\t0.0000\t0.0000\t21.4s\n",
      "4\t15\t0.7531\t5.6833\t0.7562\t0.0000\t0.0000\t0.0000\t25.7s\n",
      "5\t16\t0.7747\t5.3827\t0.7819\t0.0000\t0.0000\t0.0000\t30.2s\n",
      "6\t17\t0.7968\t5.0612\t0.8085\t0.0000\t0.0000\t0.0000\t35.2s\n",
      "7\t17\t0.8077\t4.8155\t0.8339\t0.0000\t0.0000\t0.0000\t40.0s\n",
      "8\t16\t0.8262\t4.5057\t0.8562\t0.0000\t0.0000\t0.0000\t44.8s\n",
      "9\t16\t0.8499\t4.1975\t0.8782\t0.0000\t0.0000\t0.0000\t50.0s\n",
      "10\t16\t0.8373\t4.1458\t0.8994\t0.0000\t0.0000\t0.0000\t54.9s\n",
      "11\t16\t0.8718\t3.9385\t0.9203\t0.0000\t0.0000\t0.0000\t59.8s\n",
      "12\t16\t0.8755\t3.7590\t0.9417\t0.0000\t0.0000\t0.0000\t64.8s\n",
      "13\t15\t0.9048\t3.5680\t0.9602\t0.0000\t0.0000\t0.0000\t69.9s\n",
      "14\t17\t0.8543\t3.4161\t0.9826\t0.0000\t0.0000\t0.0000\t75.4s\n",
      "15\t18\t0.8858\t3.3206\t1.0053\t0.0000\t0.0000\t0.0000\t81.0s\n",
      "16\t15\t0.9552\t3.1131\t1.0224\t0.0000\t0.0000\t0.0000\t85.8s\n",
      "17\t16\t0.9159\t3.0288\t1.0407\t0.0000\t0.0000\t0.0000\t91.2s\n",
      "18\t17\t0.9206\t3.0515\t1.0605\t0.0000\t0.0000\t0.0000\t96.8s\n",
      "19\t16\t0.9292\t2.8574\t1.0776\t0.0000\t0.0000\t0.0000\t101.9s\n",
      "20\t16\t0.8899\t2.6696\t1.0940\t0.0000\t0.0000\t0.0000\t107.0s\n",
      "21\t16\t0.9542\t2.7004\t1.1115\t0.0000\t0.0000\t0.0000\t112.1s\n",
      "22\t15\t0.9000\t2.5654\t1.1253\t0.0000\t0.0000\t0.0000\t117.2s\n",
      "23\t17\t0.9262\t2.5849\t1.1394\t0.0000\t0.0000\t0.0000\t122.6s\n",
      "24\t16\t0.9107\t2.5142\t1.1548\t0.0667\t1.0000\t0.0667\t128.0s\n",
      "25\t16\t0.8841\t2.4445\t1.1656\t0.1333\t2.0000\t0.1333\t133.3s\n",
      "26\t15\t0.8996\t2.4148\t1.1767\t0.0667\t1.0000\t0.0667\t138.3s\n",
      "27\t17\t0.8278\t2.2031\t1.1897\t0.0667\t1.0000\t0.0667\t144.3s\n",
      "28\t16\t0.7881\t2.2403\t1.2035\t0.0667\t1.0000\t0.0667\t150.0s\n",
      "29\t16\t0.8640\t2.0543\t1.2166\t0.0667\t1.0000\t0.0667\t155.2s\n",
      "30\t16\t0.8324\t2.2034\t1.2278\t0.0667\t1.0000\t0.0667\t160.6s\n",
      "31\t15\t0.8966\t2.0596\t1.2372\t0.0667\t1.0000\t0.0667\t166.1s\n",
      "32\t17\t0.8118\t2.0773\t1.2492\t0.0667\t1.0000\t0.0667\t171.5s\n",
      "33\t16\t0.8410\t2.0313\t1.2591\t0.0667\t1.0000\t0.0667\t176.9s\n",
      "34\t14\t0.7583\t2.0080\t1.2692\t0.0667\t1.0000\t0.0667\t181.9s\n",
      "35\t16\t0.8156\t2.0179\t1.2802\t0.0667\t1.0000\t0.0667\t187.6s\n",
      "36\t16\t0.8080\t2.0212\t1.2909\t0.0667\t1.0000\t0.0667\t193.3s\n",
      "37\t16\t0.7654\t1.9320\t1.3026\t0.0667\t1.0000\t0.0667\t198.8s\n",
      "38\t17\t0.6780\t1.8799\t1.3128\t0.0667\t1.0000\t0.0667\t204.5s\n",
      "39\t16\t0.6615\t1.9171\t1.3208\t0.0667\t1.0000\t0.0667\t210.2s\n",
      "40\t15\t0.6589\t1.8041\t1.3306\t0.0667\t1.0000\t0.0667\t215.6s\n",
      "41\t17\t0.6543\t1.9133\t1.3394\t0.0667\t1.0000\t0.0667\t221.6s\n",
      "42\t17\t0.6422\t1.8111\t1.3490\t0.0667\t1.0000\t0.0667\t227.6s\n",
      "43\t17\t0.6215\t1.7381\t1.3589\t0.0667\t1.0000\t0.0667\t233.5s\n",
      "44\t16\t0.5946\t1.7362\t1.3680\t0.0667\t1.0000\t0.0667\t239.6s\n",
      "45\t16\t0.6011\t1.7280\t1.3780\t0.0667\t1.0000\t0.0667\t245.9s\n",
      "46\t16\t0.5295\t1.8112\t1.3885\t0.0667\t1.0000\t0.0667\t252.3s\n",
      "47\t17\t0.5489\t1.7693\t1.3977\t0.0667\t1.0000\t0.0667\t258.9s\n",
      "48\t16\t0.5692\t1.8175\t1.4066\t0.0667\t1.0000\t0.0667\t265.1s\n",
      "49\t16\t0.5173\t1.6525\t1.4125\t0.0667\t1.0000\t0.0667\t271.2s\n",
      "50\t16\t0.5000\t1.7349\t1.4217\t0.0667\t1.0000\t0.0667\t277.5s\n",
      "51\t17\t0.5167\t1.6658\t1.4308\t0.0667\t1.0000\t0.0667\t284.5s\n",
      "52\t16\t0.4504\t1.6744\t1.4381\t0.0667\t1.0000\t0.0667\t291.0s\n",
      "53\t16\t0.4556\t1.6942\t1.4434\t0.0667\t1.0000\t0.0667\t297.7s\n",
      "54\t16\t0.5191\t1.5968\t1.4478\t0.0667\t1.0000\t0.0667\t304.5s\n",
      "55\t17\t0.4713\t1.5563\t1.4529\t0.0667\t1.0000\t0.0667\t312.3s\n",
      "56\t16\t0.3897\t1.6278\t1.4584\t0.0667\t1.0000\t0.0667\t318.9s\n",
      "57\t17\t0.4076\t1.5703\t1.4676\t0.0667\t1.0000\t0.0667\t326.4s\n",
      "58\t17\t0.3991\t1.5448\t1.4754\t0.0667\t1.0000\t0.0667\t333.2s\n",
      "59\t16\t0.4024\t1.4273\t1.4821\t0.0667\t1.0000\t0.0667\t339.8s\n",
      "60\t17\t0.3910\t1.5531\t1.4881\t0.0667\t1.0000\t0.0667\t346.4s\n",
      "61\t16\t0.3694\t1.5586\t1.4930\t0.0667\t1.0000\t0.0667\t352.8s\n",
      "62\t16\t0.3451\t1.4748\t1.4990\t0.0667\t1.0000\t0.0667\t359.2s\n",
      "63\t16\t0.3633\t1.4377\t1.5050\t0.0667\t1.0000\t0.0667\t365.6s\n",
      "64\t15\t0.3169\t1.4942\t1.5100\t0.0667\t1.0000\t0.0667\t371.7s\n",
      "65\t16\t0.3545\t1.4772\t1.5144\t0.0667\t1.0000\t0.0667\t378.2s\n",
      "66\t16\t0.2977\t1.2877\t1.5197\t0.0667\t1.0000\t0.0667\t385.1s\n",
      "67\t16\t0.3090\t1.4475\t1.5263\t0.0667\t1.0000\t0.0667\t391.7s\n",
      "68\t15\t0.3400\t1.4742\t1.5302\t0.0667\t1.0000\t0.0667\t398.1s\n",
      "69\t16\t0.3111\t1.3888\t1.5346\t0.0667\t1.0000\t0.0667\t404.9s\n",
      "70\t15\t0.2820\t1.4191\t1.5377\t0.0667\t1.0000\t0.0667\t413.5s\n",
      "71\t17\t0.3257\t1.4304\t1.5410\t0.0667\t1.0000\t0.0667\t420.8s\n",
      "72\t15\t0.2708\t1.5468\t1.5429\t0.0667\t1.0000\t0.0667\t427.3s\n",
      "73\t15\t0.2679\t1.3469\t1.5460\t0.0667\t1.0000\t0.0667\t433.6s\n",
      "74\t15\t0.2495\t1.4022\t1.5510\t0.0667\t1.0000\t0.0667\t440.1s\n",
      "75\t16\t0.2617\t1.5706\t1.5506\t0.0667\t1.0000\t0.0667\t446.9s\n",
      "76\t16\t0.2319\t1.4990\t1.5497\t0.0667\t1.0000\t0.0667\t454.0s\n",
      "77\t16\t0.2341\t1.5124\t1.5494\t0.0667\t1.0000\t0.0667\t461.0s\n",
      "78\t17\t0.2385\t1.4502\t1.5510\t0.0667\t1.0000\t0.0667\t468.4s\n",
      "79\t15\t0.2335\t1.3966\t1.5523\t0.0667\t1.0000\t0.0667\t475.5s\n",
      "80\t16\t0.2086\t1.3458\t1.5565\t0.0667\t1.0000\t0.0667\t483.0s\n",
      "81\t17\t0.2140\t1.3923\t1.5592\t0.0667\t1.0000\t0.0667\t490.6s\n",
      "82\t15\t0.2302\t1.4240\t1.5588\t0.0667\t1.0000\t0.0667\t497.7s\n",
      "83\t16\t0.1711\t1.2798\t1.5602\t0.0667\t1.0000\t0.0667\t505.3s\n",
      "84\t16\t0.1846\t1.3604\t1.5635\t0.0667\t1.0000\t0.0667\t512.4s\n",
      "85\t17\t0.1780\t1.3133\t1.5678\t0.0667\t1.0000\t0.0667\t520.1s\n",
      "86\t15\t0.1746\t1.2867\t1.5727\t0.0667\t1.0000\t0.0667\t527.1s\n",
      "87\t16\t0.1870\t1.2292\t1.5770\t0.0667\t1.0000\t0.0667\t534.3s\n",
      "88\t15\t0.2002\t1.3122\t1.5777\t0.0667\t1.0000\t0.0667\t541.0s\n",
      "89\t16\t0.1645\t1.4925\t1.5782\t0.0667\t1.0000\t0.0667\t548.3s\n",
      "90\t16\t0.1682\t1.1659\t1.5807\t0.0667\t1.0000\t0.0667\t555.6s\n",
      "91\t16\t0.1537\t1.2369\t1.5851\t0.0667\t1.0000\t0.0667\t562.7s\n",
      "92\t16\t0.1518\t1.2558\t1.5896\t0.0667\t1.0000\t0.0667\t569.8s\n",
      "93\t15\t0.1676\t1.4105\t1.5925\t0.0667\t1.0000\t0.0667\t577.0s\n",
      "94\t14\t0.1409\t1.1890\t1.5935\t0.0667\t1.0000\t0.0667\t583.6s\n",
      "95\t16\t0.1362\t1.1468\t1.5998\t0.0667\t1.0000\t0.0667\t590.7s\n",
      "96\t17\t0.1188\t1.2604\t1.6033\t0.0667\t1.0000\t0.0667\t598.1s\n",
      "97\t15\t0.1393\t1.2234\t1.6054\t0.0667\t1.0000\t0.0667\t604.9s\n",
      "98\t16\t0.1506\t1.2298\t1.6088\t0.0667\t1.0000\t0.0667\t612.0s\n",
      "99\t17\t0.1309\t1.1696\t1.6124\t0.0667\t1.0000\t0.0667\t619.4s\n",
      "100\t15\t0.1331\t1.2434\t1.6146\t0.0667\t1.0000\t0.0667\t626.2s\n",
      "101\t16\t0.1146\t1.2809\t1.6161\t0.0000\t0.0000\t0.0000\t633.3s\n",
      "102\t16\t0.1226\t1.2829\t1.6150\t0.0000\t0.0000\t0.0000\t640.4s\n",
      "103\t17\t0.0989\t1.1360\t1.6158\t0.0000\t0.0000\t0.0000\t648.1s\n",
      "104\t16\t0.1074\t1.2636\t1.6173\t0.0000\t0.0000\t0.0000\t655.2s\n",
      "105\t16\t0.1144\t1.2719\t1.6190\t0.0000\t0.0000\t0.0000\t662.8s\n",
      "106\t16\t0.0940\t1.2713\t1.6181\t0.0000\t0.0000\t0.0000\t670.0s\n",
      "107\t17\t0.0889\t1.3325\t1.6190\t0.0000\t0.0000\t0.0000\t677.9s\n",
      "108\t15\t0.0915\t1.1564\t1.6198\t0.0000\t0.0000\t0.0000\t684.8s\n",
      "109\t17\t0.1049\t1.2264\t1.6201\t0.0000\t0.0000\t0.0000\t692.9s\n",
      "110\t17\t0.0878\t1.3141\t1.6164\t0.0000\t0.0000\t0.0000\t700.5s\n",
      "111\t15\t0.0987\t1.1699\t1.6175\t0.0000\t0.0000\t0.0000\t707.7s\n",
      "112\t15\t0.0937\t1.1088\t1.6195\t0.0000\t0.0000\t0.0000\t714.6s\n",
      "113\t16\t0.0939\t1.1445\t1.6233\t0.0000\t0.0000\t0.0000\t722.0s\n",
      "114\t16\t0.0843\t1.0931\t1.6262\t0.0000\t0.0000\t0.0000\t729.4s\n",
      "115\t15\t0.1047\t1.1819\t1.6263\t0.0000\t0.0000\t0.0000\t736.4s\n",
      "116\t17\t0.0599\t1.1661\t1.6280\t0.0000\t0.0000\t0.0000\t744.4s\n",
      "117\t17\t0.0775\t1.1633\t1.6262\t0.0000\t0.0000\t0.0000\t752.2s\n",
      "118\t15\t0.0872\t1.2429\t1.6248\t0.0000\t0.0000\t0.0000\t759.4s\n",
      "119\t16\t0.0712\t1.0836\t1.6263\t0.0000\t0.0000\t0.0000\t766.9s\n",
      "120\t16\t0.0734\t1.0278\t1.6297\t0.0000\t0.0000\t0.0000\t774.3s\n",
      "121\t16\t0.0593\t1.0224\t1.6340\t0.0000\t0.0000\t0.0000\t781.9s\n",
      "122\t16\t0.0686\t1.1054\t1.6369\t0.0000\t0.0000\t0.0000\t789.5s\n",
      "123\t15\t0.0731\t1.1697\t1.6375\t0.0000\t0.0000\t0.0000\t796.6s\n",
      "124\t16\t0.0690\t1.2042\t1.6375\t0.0000\t0.0000\t0.0000\t804.4s\n",
      "125\t16\t0.0488\t1.0499\t1.6379\t0.0000\t0.0000\t0.0000\t811.8s\n",
      "126\t17\t0.0683\t1.1530\t1.6387\t0.0000\t0.0000\t0.0000\t819.7s\n",
      "127\t16\t0.0673\t1.0909\t1.6395\t0.0000\t0.0000\t0.0000\t827.2s\n",
      "128\t15\t0.0640\t1.1327\t1.6398\t0.0000\t0.0000\t0.0000\t834.3s\n",
      "129\t17\t0.0573\t1.2412\t1.6414\t0.0000\t0.0000\t0.0000\t842.6s\n",
      "130\t16\t0.0570\t1.1020\t1.6412\t0.0000\t0.0000\t0.0000\t850.0s\n",
      "131\t17\t0.0537\t1.0530\t1.6414\t0.0000\t0.0000\t0.0000\t859.0s\n",
      "132\t16\t0.0654\t1.0431\t1.6420\t0.0000\t0.0000\t0.0000\t866.8s\n",
      "133\t15\t0.0615\t1.1216\t1.6433\t0.0000\t0.0000\t0.0000\t873.8s\n",
      "134\t16\t0.0374\t0.9483\t1.6487\t0.0000\t0.0000\t0.0000\t881.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\t17\t0.0534\t1.0342\t1.6502\t0.0000\t0.0000\t0.0000\t889.1s\n",
      "136\t16\t0.0601\t1.0182\t1.6485\t0.0000\t0.0000\t0.0000\t896.9s\n",
      "137\t16\t0.0414\t1.0311\t1.6488\t0.0000\t0.0000\t0.0000\t904.5s\n",
      "138\t17\t0.0470\t0.9462\t1.6495\t0.0000\t0.0000\t0.0000\t912.0s\n",
      "139\t18\t0.0381\t1.0575\t1.6508\t0.0000\t0.0000\t0.0000\t919.7s\n",
      "140\t16\t0.0375\t1.0448\t1.6503\t0.0000\t0.0000\t0.0000\t926.8s\n",
      "141\t15\t0.0432\t1.0302\t1.6521\t0.0000\t0.0000\t0.0000\t933.5s\n",
      "142\t17\t0.0364\t1.0478\t1.6517\t0.0000\t0.0000\t0.0000\t940.9s\n",
      "143\t16\t0.0342\t1.0406\t1.6504\t0.0000\t0.0000\t0.0000\t948.0s\n",
      "144\t16\t0.0370\t1.0710\t1.6499\t0.0000\t0.0000\t0.0000\t955.4s\n",
      "145\t17\t0.0435\t0.9777\t1.6498\t0.0000\t0.0000\t0.0000\t963.2s\n",
      "146\t16\t0.0371\t0.9517\t1.6546\t0.0000\t0.0000\t0.0000\t970.6s\n",
      "147\t15\t0.0328\t0.9573\t1.6583\t0.0000\t0.0000\t0.0000\t977.9s\n",
      "148\t16\t0.0338\t1.0063\t1.6589\t0.0000\t0.0000\t0.0000\t985.2s\n",
      "149\t17\t0.0314\t0.9072\t1.6620\t0.0000\t0.0000\t0.0000\t992.8s\n",
      "150\t15\t0.0311\t0.9923\t1.6634\t0.0000\t0.0000\t0.0000\t1000.4s\n",
      "151\t15\t0.0331\t1.1654\t1.6612\t0.0000\t0.0000\t0.0000\t1007.3s\n",
      "152\t17\t0.0260\t1.1328\t1.6571\t0.0000\t0.0000\t0.0000\t1015.8s\n",
      "153\t15\t0.0317\t1.0081\t1.6538\t0.0000\t0.0000\t0.0000\t1022.7s\n",
      "154\t16\t0.0371\t0.9383\t1.6537\t0.0000\t0.0000\t0.0000\t1029.9s\n",
      "155\t15\t0.0302\t0.9071\t1.6566\t0.0000\t0.0000\t0.0000\t1037.6s\n",
      "156\t17\t0.0316\t0.9598\t1.6587\t0.0000\t0.0000\t0.0000\t1045.9s\n",
      "157\t15\t0.0291\t0.8218\t1.6627\t0.0000\t0.0000\t0.0000\t1052.7s\n",
      "158\t16\t0.0244\t0.9700\t1.6650\t0.0000\t0.0000\t0.0000\t1059.9s\n",
      "159\t17\t0.0239\t0.9187\t1.6662\t0.0000\t0.0000\t0.0000\t1067.5s\n",
      "160\t15\t0.0281\t1.1632\t1.6630\t0.0000\t0.0000\t0.0000\t1074.3s\n",
      "161\t15\t0.0247\t0.9950\t1.6621\t0.0000\t0.0000\t0.0000\t1081.9s\n",
      "162\t17\t0.0213\t0.9230\t1.6615\t0.0000\t0.0000\t0.0000\t1090.4s\n",
      "163\t16\t0.0207\t0.7507\t1.6634\t0.0000\t0.0000\t0.0000\t1097.6s\n",
      "164\t16\t0.0252\t0.8922\t1.6691\t0.0000\t0.0000\t0.0000\t1105.0s\n",
      "165\t16\t0.0218\t0.9846\t1.6700\t0.0000\t0.0000\t0.0000\t1112.2s\n",
      "166\t17\t0.0187\t0.8643\t1.6723\t0.0000\t0.0000\t0.0000\t1119.7s\n",
      "167\t16\t0.0198\t0.9837\t1.6716\t0.0000\t0.0000\t0.0000\t1126.8s\n",
      "168\t16\t0.0219\t1.0023\t1.6681\t0.0000\t0.0000\t0.0000\t1134.1s\n",
      "169\t16\t0.0202\t0.9306\t1.6685\t0.0000\t0.0000\t0.0000\t1141.2s\n",
      "170\t15\t0.0197\t0.9077\t1.6676\t0.0000\t0.0000\t0.0000\t1148.0s\n",
      "171\t17\t0.0188\t0.8706\t1.6680\t0.0000\t0.0000\t0.0000\t1155.6s\n",
      "172\t16\t0.0196\t0.8858\t1.6686\t0.0000\t0.0000\t0.0000\t1162.7s\n",
      "173\t15\t0.0187\t0.8767\t1.6704\t0.0000\t0.0000\t0.0000\t1169.8s\n",
      "174\t16\t0.0202\t0.9954\t1.6687\t0.0000\t0.0000\t0.0000\t1177.0s\n",
      "175\t16\t0.0127\t0.8273\t1.6723\t0.0000\t0.0000\t0.0000\t1184.4s\n",
      "176\t17\t0.0193\t0.8722\t1.6736\t0.0000\t0.0000\t0.0000\t1192.5s\n",
      "177\t16\t0.0172\t0.8222\t1.6752\t0.0000\t0.0000\t0.0000\t1200.0s\n",
      "178\t15\t0.0187\t1.0754\t1.6740\t0.0000\t0.0000\t0.0000\t1206.9s\n",
      "179\t17\t0.0117\t0.9355\t1.6726\t0.0000\t0.0000\t0.0000\t1214.5s\n",
      "180\t17\t0.0186\t0.8240\t1.6721\t0.0000\t0.0000\t0.0000\t1222.2s\n",
      "181\t15\t0.0145\t1.0294\t1.6697\t0.0000\t0.0000\t0.0000\t1229.0s\n",
      "182\t15\t0.0144\t0.9030\t1.6667\t0.0000\t0.0000\t0.0000\t1235.9s\n",
      "183\t16\t0.0174\t0.8620\t1.6647\t0.0000\t0.0000\t0.0000\t1243.5s\n",
      "184\t16\t0.0138\t0.8360\t1.6635\t0.0000\t0.0000\t0.0000\t1251.5s\n",
      "185\t15\t0.0135\t0.8453\t1.6641\t0.0000\t0.0000\t0.0000\t1258.4s\n",
      "186\t16\t0.0117\t0.7791\t1.6651\t0.0000\t0.0000\t0.0000\t1266.5s\n",
      "187\t15\t0.0126\t0.9959\t1.6663\t0.0000\t0.0000\t0.0000\t1273.9s\n",
      "188\t16\t0.0108\t0.8467\t1.6657\t0.0000\t0.0000\t0.0000\t1281.6s\n",
      "189\t16\t0.0122\t0.7039\t1.6713\t0.0000\t0.0000\t0.0000\t1289.4s\n",
      "190\t15\t0.0135\t0.9384\t1.6725\t0.0000\t0.0000\t0.0000\t1296.6s\n",
      "191\t16\t0.0093\t0.8007\t1.6740\t0.0000\t0.0000\t0.0000\t1304.3s\n",
      "192\t15\t0.0127\t0.7387\t1.6751\t0.0000\t0.0000\t0.0000\t1311.1s\n",
      "193\t16\t0.0118\t0.6389\t1.6803\t0.0000\t0.0000\t0.0000\t1319.1s\n",
      "194\t17\t0.0082\t0.8656\t1.6819\t0.0000\t0.0000\t0.0000\t1326.8s\n",
      "195\t16\t0.0088\t0.7569\t1.6846\t0.0000\t0.0000\t0.0000\t1333.9s\n",
      "196\t16\t0.0146\t0.8463\t1.6832\t0.0000\t0.0000\t0.0000\t1341.0s\n",
      "197\t15\t0.0101\t0.6941\t1.6839\t0.0000\t0.0000\t0.0000\t1348.7s\n",
      "198\t17\t0.0076\t0.7204\t1.6886\t0.0000\t0.0000\t0.0000\t1356.5s\n",
      "199\t17\t0.0061\t0.9091\t1.6875\t0.0000\t0.0000\t0.0000\t1365.2s\n",
      "200\t15\t0.0072\t0.7756\t1.6843\t0.0000\t0.0000\t0.0000\t1372.6s\n",
      "\n",
      "Training finished after 200 epochs\n",
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "from train import *\n",
    "\n",
    "data_path = \"./dumped.data\"\n",
    "log_path = \"./modLog.txt\"\n",
    "save_filename = \"projectMod\"\n",
    "model = train_model(data_path, log_path, 9510, use_gpu = False)\n",
    "save_model(save_filename, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load trained model, make predictions on test queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./projectMod.pt\n",
      "Size of model's vocab (nb_candidates): 69118\n",
      "Loading test data from ./dumped.data\n",
      "# of test queries: 500\n",
      "Writing predictions on test set to './Pred_on_test.txt'\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "print(\"Loading model from {}\".format(\"./projectMod.pt\"))\n",
    "model = torch.load(\"./projectMod.pt\")\n",
    "model_vocab_size = model.get_nb_candidates()\n",
    "print(\"Size of model's vocab (nb_candidates): {}\".format(model_vocab_size))\n",
    "\n",
    "# Load data\n",
    "print(\"Loading test data from {}\".format(\"./dumped.data\"))\n",
    "data = joblib.load(\"./dumped.data\")\n",
    "candidates = data[\"candidates\"]\n",
    "test_q_cand_ids = data[\"test_query_cand_ids\"]\n",
    "test_q_embed = make_embedder(data[\"test_query_embeds\"], grad=False, \n",
    "                                 cuda=model.use_cuda, sparse=False)\n",
    "\n",
    "# Make list of test query IDs\n",
    "print(\"# of test queries: {}\".format(test_q_embed.weight.shape[0]))\n",
    "\n",
    "# Write predictions on test set\n",
    "print(\"Writing predictions on test set to '{}'\".format(\"./Pred_on_test.txt\"))\n",
    "test_eval = Evaluator(model, test_q_embed, test_q_cand_ids)\n",
    "test_eval.write_predictions(\"./Pred_on_test.txt\", list(candidates))\n",
    "\n",
    "print(\"Done.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
